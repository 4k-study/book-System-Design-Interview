# 4장 처리율 제한 장치의 설계

처리율 제한 장치 : 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치

- HTTP 에서 특정 기간 내에 전송되는 클라이언트 요청 횟수
- API 요청 횟수가 제한 장치에 정의된 임계치를 넘어가면 추가 호출은 중단된다. (ex 초당 2회 글 게시, 한 IP에서 하루에 계정생성 10개까지만 가능, 같은 디바이스로 주당 5회 이상 리워드 요청 불가능)

제한 장치의 장점

- DoS 공격 방지
- 비용 절감
- 서버 과부하 방지

# 1단계 문제 이해 및 설계 범위 확정

처리율 제한 장치를 구현하는 데 여러가지 알고리즘을 사용하는데, 이는 각각의 장단점이 있다.

질문 할 것

- 클라이언트 제한 장치인지, 서버 제한 장치인지
- 어떤 기준을 사용해서 제어해야 하는지
- 시스템 규모
- 분산 환경인지
- 독립적인 서비스 인지
- 제한 장치에 걸린 경우 사용자에게 알려줘야 하는지
- 기타 등등

질문을 통해 요약 해야할 요구사항

- 낮은 응답시간
- 낮은 메모리 사용량
- 분산 환경
- 예외 처리
- 본 서버와 낮은 결합도

# 2단계 개략적 설계안 제시 및 동의 구하기

### 처리율 제한 장치의 위치

- 클라이언트 : 일반적으로 클라이언트 요청은 위변조가 쉬워 좋지 않다.
- 서버측
    - API 서버에 둔다.
    - API 서버로 가는 요청 사이에 둔다.
    - API 게이트 웨이

**고려사항**

- 프로그래밍 언어, 캐시 등 기술 스택
- 적절한 처리율 제한 알고리즘
- 현재 기술이 MSA + 게이트웨이 사용중이라면 게이트웨이 고려
- 직접 만들기 vs 상용 API 게이트웨이 고려

### 처리율 제한 알고리즘

- **토큰 버킷**
    - 간단하고, 보편적으로 사용한다.
    - 지정된 용량을 갖는 버킷을 두고, 토큰이 꽉 차면 추가 공급된 토큰은 버려진다.
    - 각 요청이 처리될 때마다 하나의 토큰을 사용한다.
    - 인자는 버킷 크기와, 토큰 공급률 두 가지이다.
    - 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다. (사용자마다 or IP마다 or 모든요청마다 버킷)
    - 장점
        - 구현이 쉽다.
        - 메모리가 효율적이다.
        - 높은 트래픽 처리가 가능하다.
    - 단점
        - 두 가지 인자를 튜닝하기 어렵다.
- **누출 버킷**
    - 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어있다. 보통 Queue로 구현한다.
    - 요청이 도착했을 때 큐가 비어있다면 요청을 추가하고, 꽉찼다면 새요청을 버린다.
    - 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
    - 인자는 버킷 크기와, 처리율 두 가지이다.
    - 장점
        - 큐의 크기가 제한되어 메모리 사용량이 효율적이다.
        - 고정 처리율을 갖고 있기 때문에 안정적 출력이 가능하다.
    - 단점
        - 단기간에 많은 트래픽이 몰리면 큐에 요청이 쌓이게 된다. 쌓이면 오래된 요청은 버려진다.
        - 두 가지 인자를 튜닝하기 어렵다.
- **고정 윈도 카운터**
    - 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
    - 요청이 접수될 때마다 카운터 값은 1씩 증가한다.
    - 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.
    - 장점
        - 메모리 효율이 좋다.
        - 이해하기 쉽다.
        - 특정한 트래픽 패턴을 처리하기에 적합하다.
    - 단점
        - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.
- **이동 윈도 로그**
    - 고정 윈도 카운터의 단점을 해결한 알고리즘
    - 요청의 타임스탬프를 추적한다. 타임스탬프 데이터는 보통 Redis의 SortedSet 같은 캐시에 보관한다.
    - 새 요청이 오면 만료된 타임스탬프는 제거한다. (만료된 타임스탬프는 그 값이  현재 윈도 시작지점보다 오래된 타임스탬프를 말한다.)
    - 새 요청의 타임스탬프를 로그에 추가한다.
    - 로그의 크기가 허용치보다 작거나 같으면 요청을 시스템에 전달한다. 그렇지 않으면 처리를 거부한다.
    - 장점
        - 처리율 제한 메커니즘은 아주 정교하다. 어느 순간에도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
    - 단점
        - 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.
- **이동 윈도 카운터**
    - 고정 윈도 카운터와 윈도 로깅 알고리즘을 결합한 것이다.
    - 현재 1분간의 요청수 + 직전 1분간의 요청수 * 이동 윈도 직전 1분 겹치는 비율로 현재 윈도의 요청개수를 계산한다.
    - 장점
        - 트래픽이 몰려도 잘 대응한다.
        - 메모리 효율이 좋다.
    - 단점
        - 실제 상태와 조금 다르게 허용되거나 버려지는 요청이 생긴다. (오차율 0.003%정도)

### 개략적인 아키텍처

- 추적 대상을 정하고, 카운터한다.
- 카운터는 어떻게 보관할지 정한다.

# 3단계 상세 설계

개략적 설계로는 다음과 같은 사항은 알 수가 없다.

- 처리율 제한 규칙은 어떻게 만들어지고 어떻게 저장되는가?
- 처리가 제한된 요청은 어떻게 처리되는가?

### 처리율 제한 규칙

리프트는 처리율 제한 오픈 소스를 사용한다.

### 처리율 한도 초과 트래픽의 처리

한도 제한에 걸리면 API는 429 응답을 클라이언트에게 보낸다.

경우에 따라서는 나중에 처리하기 위해 큐에 보관한다.

**HTTP 헤더**

- X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청 수
- X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

### 상세 설계

- 처리율 제한 규칙은 디스크에 보관한다.
- 작업 프로세스는 수시로 규칙을 읽어 캐시에 저장한다.

![Uploading image.png…]()

1. 클라이언트 요청은 처리율 제한 미들웨어에 도착한다.
2. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다. 아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다.
3. 가져온 값들에 근거하여 요청에 대한 결정을 내린다.

### 분산 환경에서의 처리율 제한 장치의 구현

여러대의 서버와 병렬 스레드를 지원하는 것은 두가지 어려운 문제를 풀어야 한다.

- 경쟁 조건
    - 레디스에서 카운터의 값을 읽는다.
    - 카운터 + 1 의 값이 임계치를 넘는지 본다.
    - 넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가시킨다.
    - 이는 동기화 이슈가 야기된다. (락, 루아 스크립트, sorted set등)
- 동기화
    - 고정 세션을 활용하여 동일한 클라이언트의 요청은 항상 같은 처리율 제한 장치로 보내도록 한다. (비추천)
    - 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.

**성능 최적화**

- 여러 데이터센터를 지원하는 경우 가까운 엣지 서버를 통해 latency를 줄인다.
- 장치간에 동기화 할 때 최종 일관성 모델을 사용한다.

**모니터링**

- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.

# 4단계 마무리

여러 알고리즘의 장단점을 확인하여 구현하는 아키텍처, 분산환경, 성능최적화, 모니터링등을 고려하여 선택하자.

- 경성(hard) 또는 연성(soft) 처리율 제한
    - 경성 : 요청 개수는 임계치를 절대 넘어설 수 없다.
    - 연성 : 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
    - 이번 장에서는 애플리케이션 계층에서만 봤지만, Iptables등 여러 계층에서 처리율 제한이 가능하다.
- 처리율 제한 회피 방법
    - 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄인다.
    - 처리율 제한 임계치를 정하고, 너무 많은 메시지를 보내지 않도록 한다.
    - 예외나 에러를 처리하는 코드를 도입하여 우아한 복구를 장려하자.
    - 재시도 로직을 구현할 때 충분한 백오프 시간을 둔다.
